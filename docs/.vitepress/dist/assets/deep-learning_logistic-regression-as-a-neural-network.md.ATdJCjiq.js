import{_ as a,c as t,o as i,ag as n}from"./chunks/framework.DPDPlp3K.js";const s="/img/sigmoid.jpg",o="/img/LRGDComputationGraph.jpg",$=JSON.parse('{"title":"Logistic Regression as a Neural Network","description":"","frontmatter":{"prev":{"text":"Deep Learning","link":"deep-learning/index"},"next":{"text":"Python and Vectorization","link":"deep-learning/python-and-vectorization"}},"headers":[],"relativePath":"deep-learning/logistic-regression-as-a-neural-network.md","filePath":"deep-learning/logistic-regression-as-a-neural-network.md"}'),r={name:"deep-learning/logistic-regression-as-a-neural-network.md"};function l(c,e,p,d,h,m){return i(),t("div",null,e[0]||(e[0]=[n('<h1 id="logistic-regression-as-a-neural-network" tabindex="-1">Logistic Regression as a Neural Network <a class="header-anchor" href="#logistic-regression-as-a-neural-network" aria-label="Permalink to &quot;Logistic Regression as a Neural Network&quot;">​</a></h1><h2 id="notation" tabindex="-1">Notation <a class="header-anchor" href="#notation" aria-label="Permalink to &quot;Notation&quot;">​</a></h2><ul><li><p>$(x,y)$<br> A single training example. Where $x\\in{\\mathbb{R}^{n_x}}$ ($x$ is a x-dimensional feature vector), $y\\in {(0, 1)}$.</p></li><li><p>$m:{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ..., (x^{(m)}, y^{(m)})}$ or $m={ m_{train}}$<br> A training set which contains m training examples.</p></li><li><p>$m={m_{test}}$<br> A test example set.</p></li><li><p>$X=[x^{(1)}, x^{(2)}, ..., x^{(m)}]$<br> Input training example matrix which has $n_x$ rows and $m$ columns. $X\\in{\\mathbb{R}^{n_x * m}}$.</p><div class="warning custom-block"><p class="custom-block-title">WARNING</p><p>It is not a good idea to put training examples $x^{(1)\\mathrm{T}}, ..., x^{(m)\\mathrm{T}}$ as row vectors in the matrix $X$. It will cause much more efforts when computing.</p></div></li><li><p>$Y=[y^{(1)}, y^{(2)}, ..., y^{(m)}]$<br> Output matrix which has $1$ row and $m$ columns. $Y\\in{\\mathbb{R}^{1 * m}}$.</p></li></ul><h2 id="binary-classification" tabindex="-1">Binary Classification <a class="header-anchor" href="#binary-classification" aria-label="Permalink to &quot;Binary Classification&quot;">​</a></h2><p>Logistic regression is an algorithm for binary classification (Used for the supervised learning problem which the output labels $y$ are all either 0 or 1).</p><p><strong>Scenario example</strong><br> Take a picture as an input, and want to get a label for output to infer whether the picture is a cat. Define the output label $y$ is <code>1</code> as the picture is the case of a cat picture, and the output label is <code>0</code> as the picture is the case of not a cat picture.</p><div class="tip custom-block"><p class="custom-block-title">To Be Specific</p><p>Say, the picture is 64 × 64 pixels. And it can be divided as 3 matrices representing the red, green and blue channel.</p><p>Define the feature vector $x$ as the every elements unroll by the color matrices. So, the dimension of the feature vector $x$ is 12288. Marked as:<br> $$n=n_x=12288$$</p><p>Goal: Classifier $x-&gt;y$ can predict whether the label $y$ is <code>1</code> or <code>0</code>.</p></div><h2 id="logistic-regression" tabindex="-1">Logistic Regression <a class="header-anchor" href="#logistic-regression" aria-label="Permalink to &quot;Logistic Regression&quot;">​</a></h2><p><strong>Example</strong><br> Given a feature vector $x$ and wanting to know the probability $\\hat{y}$ of output label $y = 1$ (i.e. $\\hat{y}=P(y=1|x)$).</p><p><em>Parameters</em><br> $w\\in{\\mathbb{R}^{n_x}}, b\\in{\\mathbb{R}}$</p><p>*<em>$w$ stand for weight, which could tell the algorithm where to focus on. $b$ stand for bias, which could make sure that the neuron will be activate meaningfully (i.e. How high the weighted sum needs to be before the neuron starts getting meaningfully active.).</em></p><p><em>Output</em><br> $\\hat{y}=w^\\mathrm{T}x+b$ (Linear Regression. Will not be worked, $\\hat{y}$ is not between 0 and 1.)</p><p>$\\hat{y}=\\sigma(w^\\mathrm{T}x+b)$ (Sigmoid Function, i.e. $\\sigma(z)=\\frac{1}{1+e^{-z}}$)</p><div class="tip custom-block"><p class="custom-block-title">About Sigmoid Function</p><p><em>The graph of sigmoid function</em></p><div align="center"><img src="'+s+'" alt="Sigmoid Function"></div><div align="center">[Sigmoid Function]</div><p><em>Features</em><br> $\\lim \\limits_{z \\to +\\infty} \\sigma(z) = 1$<br> $\\lim \\limits_{z \\to -\\infty} \\sigma(z) = 0$</p></div><h2 id="logistic-regression-cost-function" tabindex="-1">Logistic Regression Cost Function <a class="header-anchor" href="#logistic-regression-cost-function" aria-label="Permalink to &quot;Logistic Regression Cost Function&quot;">​</a></h2><p>Using a cost function to train the parameters $w$ and $b$ of the logistic regression model.</p><h3 id="loss-error-function" tabindex="-1">Loss (Error) Function <a class="header-anchor" href="#loss-error-function" aria-label="Permalink to &quot;Loss (Error) Function&quot;">​</a></h3><p>A function used to measure how well the algorithm is doing. (For single training example)</p><ul><li><p>Square Error<br> $$\\mathcal{L}(\\hat{y}, y) =\\frac{(\\hat{y}-y)^{2}}{2}$$<br> Not usually use. The optimization problem always becomes non-convex. Therefore, there will be more than one multiple local optima. It can not using for gradient descent to find the global optimum.</p></li><li><p>Cross-Entropy Loss Function<br> $$\\mathcal{L}(\\hat{y}, y) =-[y \\log (\\hat{y})+(1-y) \\log (1-\\hat{y})]$$<br> The lower value of loss function is, the better prediction of algorithm is.</p><p><strong>[Analyse]</strong></p><ul><li>If $y=1$, $\\mathcal{L}(\\hat{y}, y)=-\\log (\\hat{y})$.<br> When $\\mathcal{L}$ is small, $\\log (\\hat{y})$ should be large, and $\\hat{y}$ should be large as well but no more than $1$.</li><li>If $y=0$, $\\mathcal{L}(\\hat{y}, y)=-\\log (1-\\hat{y})$.<br> When $\\mathcal{L}$ is small, $log (1-\\hat{y})$ should be large, and $\\hat{y}$ should be small but no less than $0$.</li></ul></li></ul><h3 id="cost-function" tabindex="-1">Cost Function <a class="header-anchor" href="#cost-function" aria-label="Permalink to &quot;Cost Function&quot;">​</a></h3><p>A function used to measure how well the algorithm is doing. (For the whole training set)</p><p>$$J(w, b)=\\frac{1}{m} \\sum_{i=1}^{m}L(\\hat{y}^{(i)}, y^{(i)})=-\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log (\\hat{y}^{(i)})+(1-y^{(i)}) \\log (1-\\hat{y}^{(i)})]$$<br> Still, the lower value of cost function is, the better prediction of algorithm is.</p><h2 id="gradient-descent" tabindex="-1">Gradient Descent <a class="header-anchor" href="#gradient-descent" aria-label="Permalink to &quot;Gradient Descent&quot;">​</a></h2><p>A algorithm to train (learn) the parameters $w$ and $b$ on the training set. Take all the $w$ and $b$ as the parameters, the gradient descent algorithm will find out the global optimum which is the point can having the smallest value of cost function. In another word, gradient descent tells what nudges to all of the weights and biases cause the fastest change to the value of the cost function. (i.e. Which changes to weights matter the most.)</p><p><strong>[Analyse]</strong><br> Only analyse the value $J(w)$ and parameter $w$. Assume that the funtion $J(w)$ is a convex function. Repeat this algorithm until the algorithm converges.</p><p><embed id="gradientDescent" src="/img/gradientDescent.svg"></p><p>*<em>$\\alpha$ is the <strong>learning rate</strong>. It controls how big a strep the algorithm take on each iteration.</em><br> *<em>When writing code, $\\frac{d J(w)}{d w}$ will be defined as <code>dw</code>.</em></p><p>And for the real cost function, the gradient descent will be like:</p><p><embed id="gradientDescent" src="/img/gradientDescent_real.svg"></p><p>*<em>When writing code, $\\frac{\\partial J(w, b)}{\\partial w}$ will be defined as <code>dw</code>, and $\\frac{\\partial J(w, b)}{\\partial b}$ will be defined as <code>db</code>.</em><br> *<em>Also, a coding convention <code>dvar</code> represent the derivative of a final output variable with respect to various intermediate quantities</em></p><h2 id="logistic-regression-gradient-descent" tabindex="-1">Logistic Regression Gradient Descent <a class="header-anchor" href="#logistic-regression-gradient-descent" aria-label="Permalink to &quot;Logistic Regression Gradient Descent&quot;">​</a></h2><p><strong>[Analyse]</strong><br> For a training example which has two features.</p><p>$z=w^\\mathrm{T}x+b$<br> $\\hat{y}=a=\\sigma(z)$<br> $\\mathcal{L}(a, y)=-[y \\log (\\hat{y})+(1-y) \\log (1-\\hat{y})]$<br> features: $x_1$ and $x_2$<br> parameters: $w_1$, $w_2$ and $b$</p><p><img src="'+o+`" alt="Logistic Regression Gradient Descent Computation Graph"></p><p><code>da</code>:<br> $$ \\frac{\\partial \\mathcal{L}(a, y)}{\\partial a}=-\\frac{y}{a}+\\frac{1-y}{1-a}$$</p><p><code>dz</code>:<br><embed id="LRGD_da" style="display:block;margin:auto;" src="/img/LRGD_dz.svg"></p><p><code>dw1</code>:<br> $$ \\frac{\\partial \\mathcal{L}(a, y)}{\\partial w_{1}}=x_{1} \\cdot d z$$</p><p><code>dw2</code>:<br> $$ \\frac{\\partial \\mathcal{L}(a, y)}{\\partial w_{2}}=x_{2} \\cdot d z$$</p><p><code>db</code>:<br> $$ \\frac{\\partial \\mathcal{L}(a, y)}{\\partial b}=d z$$</p><p><embed id="LRGD_da" src="/img/LRGD_repeat.svg"><br> *<em>In this repeat loop, $dw_1$ means <code>dw1</code>, and $dw_2$ means <code>dw2</code>, $db$ means <code>db</code> as well.</em></p><h3 id="gradient-descent-on-m-examples-training-set" tabindex="-1">Gradient Descent on m Examples Training Set <a class="header-anchor" href="#gradient-descent-on-m-examples-training-set" aria-label="Permalink to &quot;Gradient Descent on m Examples Training Set&quot;">​</a></h3><p><strong>[Analyse]</strong><br> For a m training examples training set, and each training example have two features.</p><p>$z=w^\\mathrm{T}x^{(i)}+b$<br> $\\hat{y}^{(i)}=a^{(i)}=\\sigma(z)$<br> $J(w,b)=\\frac{1}{m} \\sum_{i=1}^{m}L(a^{(i)}, y^{(i)})$</p><p>features: $x_1^{(i)}$ and $x_2^{(i)}$<br> parameters: $w_1$, $w_2$ and $b$</p><p>Overall training set gradient descent with the respect of $w_1$:<br> $$ \\frac{\\partial J(w, b)}{\\partial w_{1}}=\\frac{1}{m} \\sum_{i=1}^{m} \\frac{\\partial \\mathcal{L}(a, y)}{\\partial w_{1}}$$</p><p>For single training example $(x^{(i)},y^{(i)})$, use the algorithm showed before. Then add up and divided by m to get the overall result:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>// Initialize</span></span>
<span class="line"><span>J = 0;</span></span>
<span class="line"><span>dw1 = 0;  // as a accumulator for whole training set</span></span>
<span class="line"><span>dw2 = 0;  // as a accumulator for whole training set</span></span>
<span class="line"><span>db = 0;  // as a accumulator for whole training set</span></span>
<span class="line"><span></span></span>
<span class="line"><span>// Add up</span></span>
<span class="line"><span>for(i = 1 to m) {</span></span>
<span class="line"><span>  z(i) = wT x(i) + b;</span></span>
<span class="line"><span>  a(i) = σ(z(i));</span></span>
<span class="line"><span>  J += -[y(i) log(a(i)) + (1 - y(i)) log(1 - a(i))];</span></span>
<span class="line"><span>  dz(i) = a(i) - y(i);</span></span>
<span class="line"><span>  dw1 += x1(i) dz(i);</span></span>
<span class="line"><span>  dw2 += x2(i) dz(i);</span></span>
<span class="line"><span>  db += dz(i);</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>// Get average</span></span>
<span class="line"><span>J /= m;</span></span>
<span class="line"><span>dw1 /= m;  // geting the value of dJ/dw1</span></span>
<span class="line"><span>dw2 /= m;  // geting the value of dJ/dw2</span></span>
<span class="line"><span>db /= m;  // geting the value of dJ/db</span></span></code></pre></div><p><embed id="LRGD_da" src="/img/LRGD_repeat.svg"><br> *<em>For every repeat, the <code>dw1</code>, <code>dw2</code> and <code>db</code> should be calculate again.</em></p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>In the algorithm, there are two for-loop nested (The second for-loop used for calculate every $w$s and $b$s with the respect to every features). When having a large scale training set it will run less efficiency. Using vectorization to solve this problem.</p></div>`,49)]))}const u=a(r,[["render",l]]);export{$ as __pageData,u as default};
